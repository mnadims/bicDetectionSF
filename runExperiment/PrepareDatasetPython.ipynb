{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a28d5b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenize\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "\n",
    "def get_token_list(filePath):\n",
    "    with open(filePath, 'rb') as f:\n",
    "        tokens = tokenize.tokenize(f.readline)\n",
    "        file_tokens = []\n",
    "        for token in tokens:\n",
    "            file_tokens.append(tokenize.tok_name[token.type])\n",
    "            \n",
    "    return file_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b81fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/mdn769/BugFixStatistics/SCGrunable/runable/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cc9edb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working for: (3121/3122), swift_fa3c871f0b1544f859bacf38497580afd69ced0b.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' This will find a list of unique token sequences (TS Features) from all the files in this subject system. Each item of the list will be\n",
    "the feature name of the dataset to be prepared. \n",
    "'''\n",
    "list_ts_features = []\n",
    "count = 0\n",
    "inPath = file_path+ \"patch_source/openstack/added/\"\n",
    "totalFiles = len(os.listdir(inPath))\n",
    "for file in os.listdir(inPath):   \n",
    "#     if(count == 5):\n",
    "#         break\n",
    "    #print(file.split('.')[-1])\n",
    "    if(file.split('.')[-1]==\"py\"):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Working for: (\"+str(count)+\"/\"+str(totalFiles)+\")\" + \", \"+ file)    \n",
    "        try:\n",
    "            file_tokens = get_token_list(inPath+file)\n",
    "#             print(file_tokens)\n",
    "#             print(\"\\n\\n******\\n\\n\")\n",
    "                        \n",
    "            for ngram in [2, 3]: #n-gram = 2 & 3\n",
    "                temp=zip(*[file_tokens[i:] for i in range(0, ngram)]) \n",
    "                ans=[' '.join(ngram) for ngram in temp]\n",
    "            \n",
    "            for a in ans:\n",
    "                if(a not in list_ts_features):\n",
    "                    list_ts_features.append(a)\n",
    "                    \n",
    "        except: print() #do nothing...\n",
    "\n",
    "    count+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de6862ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 ['ENCODING NAME NAME', 'NAME NAME OP', 'NAME OP NAME', 'OP NAME NAME', 'NAME NAME NAME', 'NAME OP NEWLINE', 'OP NEWLINE NAME', 'NEWLINE NAME OP', 'OP NAME OP', 'NAME OP OP', 'OP OP NEWLINE', 'NAME OP NL', 'OP NL STRING', 'NL STRING OP', 'STRING OP NL', 'OP NL NAME', 'NL NAME OP', 'NAME OP STRING', 'OP STRING NEWLINE', 'STRING NEWLINE NAME', 'NEWLINE NAME NAME', 'OP OP NAME', 'OP STRING OP', 'STRING OP OP', 'OP NAME NEWLINE', 'NAME NEWLINE NAME', 'OP STRING NL', 'STRING NL STRING', 'STRING OP NEWLINE', 'NEWLINE NAME NEWLINE', 'OP OP NUMBER', 'OP NUMBER OP', 'NUMBER OP NEWLINE', 'NAME OP NUMBER', 'NAME NAME NEWLINE', 'OP NEWLINE STRING', 'NEWLINE STRING NEWLINE', 'OP NL OP', 'NL OP STRING', 'STRING OP STRING', 'STRING OP NAME', 'NUMBER OP NUMBER', 'NUMBER OP OP', 'OP OP NL', 'STRING OP NUMBER', 'NUMBER OP NL', 'OP OP OP', 'OP NEWLINE ENDMARKER', 'OP OP STRING', 'OP NEWLINE OP', 'NEWLINE OP NAME', 'STRING NEWLINE OP', 'OP NAME NL', 'NAME NL OP', 'NL OP NEWLINE', 'OP NEWLINE COMMENT', 'NEWLINE COMMENT NL', 'COMMENT NL NAME', 'NAME NEWLINE COMMENT', 'COMMENT NL COMMENT', 'NL COMMENT NL', 'OP NUMBER NEWLINE', 'NUMBER NEWLINE NAME', 'NL NAME NEWLINE', 'NL OP OP', 'NEWLINE NAME NUMBER', 'NAME NUMBER OP', 'NUMBER OP NAME', 'NAME NAME STRING', 'NAME STRING OP', 'NAME OP COMMENT', 'OP COMMENT NL', 'COMMENT NL STRING', 'NAME NEWLINE ENDMARKER', 'OP STRING NAME', 'STRING NAME NAME', 'COMMENT NL ENDMARKER', 'NL OP NAME', 'NEWLINE NAME STRING', 'NAME STRING NAME', 'ENCODING NUMBER NUMBER', 'NUMBER NUMBER OP', 'OP NEWLINE NUMBER', 'NEWLINE NUMBER NUMBER', 'ENCODING NAME OP', 'ENCODING COMMENT NL', 'NL STRING NL', 'NAME NAME COMMENT', 'NAME COMMENT NEWLINE', 'COMMENT NEWLINE NAME', 'NL OP NL', 'NL NAME NAME', 'NEWLINE STRING OP', 'STRING NL OP', 'STRING OP COMMENT', 'OP COMMENT NEWLINE', 'ENCODING NAME NUMBER', 'NAME NUMBER NAME', 'NUMBER NAME NAME', 'NAME NAME NUMBER', 'NAME NUMBER NUMBER', 'NUMBER NUMBER NAME', 'NUMBER NEWLINE NUMBER', 'NEWLINE NUMBER OP', 'OP NAME NUMBER', 'NAME STRING STRING', 'STRING STRING NAME', 'NAME STRING NEWLINE', 'STRING NAME NL', 'NAME NL STRING', 'STRING NAME OP', 'OP NUMBER NAME', 'NUMBER NAME STRING', 'STRING NEWLINE COMMENT', 'STRING NAME STRING', 'NUMBER NEWLINE ENDMARKER', 'NAME NEWLINE OP', 'NL NAME STRING', 'NAME NL NAME', 'NL NAME NL', 'STRING NL NAME', 'NUMBER OP STRING', 'NAME NL COMMENT', 'OP NL COMMENT', 'OP NAME STRING', 'ENCODING NAME STRING', 'NEWLINE OP STRING', 'NEWLINE COMMENT NEWLINE', 'COMMENT NEWLINE COMMENT', 'ENCODING OP NAME', 'OP NL NUMBER', 'NL NUMBER OP', 'NAME NAME NL', 'ENCODING STRING NEWLINE', 'NAME NEWLINE STRING', 'NEWLINE STRING NAME', 'NAME NUMBER NEWLINE', 'NAME NEWLINE NUMBER', 'NEWLINE OP OP', 'COMMENT NL OP', 'COMMENT NEWLINE STRING', 'STRING NEWLINE STRING', 'STRING NEWLINE ENDMARKER', 'COMMENT NEWLINE NUMBER', 'NUMBER NEWLINE COMMENT', 'NAME NAME ERRORTOKEN', 'NAME ERRORTOKEN NAME', 'ERRORTOKEN NAME NAME', 'ENCODING STRING OP', 'STRING NL COMMENT', 'NUMBER NAME OP', 'STRING NEWLINE NUMBER', 'NL STRING NEWLINE', 'NUMBER NAME NUMBER', 'NUMBER NEWLINE STRING', 'NAME ERRORTOKEN ERRORTOKEN', 'ERRORTOKEN ERRORTOKEN NAME', 'ERRORTOKEN NAME ERRORTOKEN', 'ERRORTOKEN NAME OP', 'OP NAME ERRORTOKEN', 'NAME ERRORTOKEN NEWLINE', 'ERRORTOKEN NEWLINE OP', 'COMMENT NEWLINE OP', 'OP NUMBER COMMENT', 'NUMBER COMMENT NEWLINE', 'STRING STRING OP', 'NEWLINE OP NL', 'OP STRING COMMENT', 'STRING COMMENT NEWLINE', 'OP NEWLINE NL', 'NEWLINE NL NAME', 'OP OP COMMENT', 'NL STRING COMMENT', 'STRING COMMENT NL', 'NUMBER OP COMMENT', 'NUMBER NAME NL', 'OP STRING STRING', 'STRING STRING NEWLINE', 'OP NUMBER NL', 'NUMBER NL NAME', 'NEWLINE NAME COMMENT', 'STRING STRING STRING', 'OP NAME COMMENT', 'NAME STRING NL', 'NAME COMMENT NL', 'ENCODING NAME NEWLINE', 'STRING NEWLINE NL', 'NEWLINE NUMBER NAME', 'NAME ERRORTOKEN OP', 'ERRORTOKEN OP NEWLINE', 'NUMBER NAME NEWLINE', 'NEWLINE OP NEWLINE', 'NUMBER NEWLINE OP', 'NL STRING NAME', 'NL OP NUMBER', 'NL NAME COMMENT', 'OP NUMBER NUMBER', 'NUMBER NL STRING', 'ENCODING NUMBER OP', 'NUMBER NL OP', 'ENCODING STRING NAME', 'NAME NUMBER STRING', 'NUMBER STRING NAME', 'ENCODING OP STRING', 'ENCODING OP OP', 'NAME NEWLINE NL', 'STRING NAME NEWLINE', 'STRING NAME NUMBER', 'ENCODING NUMBER NAME', 'COMMENT NL NUMBER', 'NAME OP ERRORTOKEN', 'OP ERRORTOKEN NAME', 'ENCODING ERRORTOKEN NAME']\n"
     ]
    }
   ],
   "source": [
    "print(len(list_ts_features), list_ts_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4207a82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working for: (3121/3122)openstack, added, swift_fa3c871f0b1544f859bacf38497580afd69ced0b.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Prepare the dataset. For each commit, list_pattern is the list of feature values. \n",
    "'''\n",
    "dataset = [[\"commit_id\", \"submodule\"] + list_ts_features] # prepare the top row of the dataset. \n",
    "#subject_systems=[\"bitcoin\", \"jenkins\", \"litecoin\", \"lucene\", \"mongo\", \"oozie\"]\n",
    "subject_systems=[\"openstack\"]\n",
    "#commit_type=[\"added\", \"deleted\"]\n",
    "commit_type=[\"added\"]\n",
    "not_worked=\"\"\n",
    "# fileContent = open(\"ssNames.txt\", \"r\", encoding='utf-8').read()\n",
    "# #print(\"Length of File Content\", len(fileContent))\n",
    "# ssNames = fileContent.split('\\n')\n",
    "\n",
    "for ss in subject_systems:\n",
    "    if(len(ss.strip()) == 0): #Ignore the last empty line....\n",
    "        break\n",
    "    for ctype in commit_type:\n",
    "        inPath = file_path+ \"patch_source/\"+ss+\"/\"+ctype+\"/\"\n",
    "        #outPath = \"xml_gml/\"+ss+\"/\"+ctype+\"/\"\n",
    "        \n",
    "        count = 0\n",
    "        totalFiles = len(os.listdir(inPath))\n",
    "        for file in os.listdir(inPath):   \n",
    "#             if(count == 10):\n",
    "#                 break\n",
    "            #print(inPath+file)\n",
    "            if(file.split('.')[-1]==\"py\"):\n",
    "                clear_output(wait=True)\n",
    "                print(\"Working for: (\"+str(count)+\"/\"+str(totalFiles)+\")\"+ss+\", \"+ctype+\", \"+file)    \n",
    "                try:\n",
    "                    file_tokens = get_token_list(inPath+file)\n",
    "\n",
    "                    list_ts = []\n",
    "                    for ngram in [2, 3]: #n-gram = 2 & 3\n",
    "                        temp=zip(*[file_tokens[i:] for i in range(0, ngram)]) \n",
    "                        list_ts +=[' '.join(ngram) for ngram in temp]\n",
    "                    \n",
    "                    countedValues = Counter(list_ts)\n",
    "                    #print(countedValues)\n",
    "                    \n",
    "                    #file := 'submodule_commitid_ext: swift_fa3c871f0b1544f859bacf38497580afd69ced0b.py'\n",
    "                    result_row = [file.split('.')[0].split('_')[1], file.split('.')[0].split('_')[0]] #Take only the commit name from the file\n",
    "                    ZeroLine = 0 #Checks if all the values in this row is zero\n",
    "                    for lp in list_ts_features:\n",
    "                        if(countedValues[lp] > 0):\n",
    "                            ZeroLine += 1\n",
    "                            result_row.append(countedValues[lp]) \n",
    "                        else: \n",
    "                            result_row.append(0)\n",
    "                    \n",
    "                    if(ZeroLine > 0):\n",
    "                        dataset.append(result_row)\n",
    "\n",
    "                except: print() #do nothing...\n",
    "                    \n",
    "            count+=1\n",
    "                \n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "618d1522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openstack\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ss)\n",
    "print(not_worked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9bcaa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dataset).to_csv(ss+'_ts_dataset.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
