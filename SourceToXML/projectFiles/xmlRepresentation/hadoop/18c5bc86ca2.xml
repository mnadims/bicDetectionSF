<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<unit xmlns="http://www.srcML.org/srcML/src" revision="1.0.0" language="Java" filename="E:/01Courses@USASK/CMPT898-HumanDrivenSoftwareEngineeringForScientificResearch/ProjectProgress/data_files/final_dataset/gen_patch_codes/filtered/hadoop/18c5bc86ca2.java"><expr_stmt><expr><name>From</name> <literal type="number">18c5bc86ca256beb9d4ccd6588c0b0ebe9dfcbd0</literal> <name>Mon</name> <name>Sep</name> <literal type="number">17</literal> <literal type="number">00</literal><operator>:</operator><literal type="number">00</literal><operator>:</operator><literal type="number">00</literal> <literal type="number">2001</literal>
<name>From</name><operator>:</operator> <name>Eli</name> <name><name>Collins</name> <argument_list type="generic">&lt;<argument><name>eli</name><annotation>@<name><name>apache</name><operator>.</operator><name>org</name></name></annotation></argument>&gt;</argument_list></name>
<name>Date</name><operator>:</operator> <name>Fri</name></expr><operator>,</operator> <expr><literal type="number">17</literal> <name>Aug</name> <literal type="number">2012</literal> <literal type="number">23</literal><operator>:</operator><literal type="number">22</literal><operator>:</operator><literal type="number">17</literal> <operator>+</operator><literal type="number">0000</literal>
<name>Subject</name><operator>:</operator> <index>[<expr><name>PATCH</name></expr>]</index> <name>HADOOP</name><operator>-</operator><literal type="number">8689.</literal> <name>Make</name> <name>trash</name> <name>a</name> <name>server</name> <name>side</name> <name>configuration</name> <name><name>option</name><operator>.</operator>
 <name>Contributed</name></name> <name>by</name> <name>Eli</name> <name>Collins</name>

<name>git</name><operator>-</operator><name>svn</name><operator>-</operator><name>id</name><operator>:</operator> <name>https</name><operator>:</operator><comment type="line">//svn.apache.org/repos/asf/hadoop/common/trunk@1374472 13f79535-47bb-0310-9956-ffa450edef68</comment>
<operator>--</operator>
 <operator>...</operator><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>/</operator><name><name>CHANGES</name><operator>.</operator><name>txt</name></name>                 <operator>|</operator>  <literal type="number">2</literal> <operator>+</operator>
 <operator>...</operator><operator>/</operator><name>java</name><operator>/</operator><name>org</name><operator>/</operator><name>apache</name><operator>/</operator><name>hadoop</name><operator>/</operator><name>fs</name><operator>/</operator><name><name>FileSystem</name><operator>.</operator><name>java</name></name> <operator>|</operator>  <literal type="number">4</literal> <operator>+</operator><operator>-</operator>
 <operator>...</operator><operator>/</operator><name>apache</name><operator>/</operator><name>hadoop</name><operator>/</operator><name>fs</name><operator>/</operator><name><name>FsServerDefaults</name><operator>.</operator><name>java</name></name>    <operator>|</operator>  <literal type="number">8</literal> <operator>++</operator><operator>-</operator>
 <operator>...</operator><operator>/</operator><name>apache</name><operator>/</operator><name>hadoop</name><operator>/</operator><name>fs</name><operator>/</operator><name><name>TrashPolicyDefault</name><operator>.</operator><name>java</name></name>  <operator>|</operator> <literal type="number">45</literal> <operator>++</operator><operator>++</operator><operator>++</operator><operator>++</operator><operator>+</operator><operator>--</operator><operator>--</operator><operator>-</operator>
 <operator>...</operator><operator>/</operator><name>apache</name><operator>/</operator><name>hadoop</name><operator>/</operator><name>fs</name><operator>/</operator><name>ftp</name><operator>/</operator><name><name>FtpConfigKeys</name><operator>.</operator><name>java</name></name>   <operator>|</operator>  <literal type="number">4</literal> <operator>+</operator><operator>-</operator>
 <operator>...</operator><operator>/</operator><name>hadoop</name><operator>/</operator><name>fs</name><operator>/</operator><name>local</name><operator>/</operator><name><name>LocalConfigKeys</name><operator>.</operator><name>java</name></name>      <operator>|</operator>  <literal type="number">4</literal> <operator>+</operator><operator>-</operator>
 <operator>...</operator><operator>/</operator><name>src</name><operator>/</operator><name>main</name><operator>/</operator><name>resources</name><operator>/</operator><name>core</name><operator>-</operator>default<operator>.</operator><name>xml</name>       <operator>|</operator> <literal type="number">11</literal> <operator>++</operator><operator>+</operator><operator>-</operator>
 <operator>...</operator><operator>/</operator><name>java</name><operator>/</operator><name>org</name><operator>/</operator><name>apache</name><operator>/</operator><name>hadoop</name><operator>/</operator><name>fs</name><operator>/</operator><name><name>TestTrash</name><operator>.</operator><name>java</name></name>  <operator>|</operator>  <literal type="number">8</literal> <operator>+</operator><operator>--</operator>
 <operator>...</operator><operator>/</operator><name>hadoop</name><operator>/</operator><name>hdfs</name><operator>/</operator><name>protocolPB</name><operator>/</operator><name><name>PBHelper</name><operator>.</operator><name>java</name></name>      <operator>|</operator>  <literal type="number">6</literal> <operator>+</operator><operator>-</operator>
 <operator>...</operator><operator>/</operator><name>hdfs</name><operator>/</operator><name>server</name><operator>/</operator><name>namenode</name><operator>/</operator><name><name>FSNamesystem</name><operator>.</operator><name>java</name></name>    <operator>|</operator>  <literal type="number">6</literal> <operator>+</operator><operator>-</operator>
 <operator>...</operator><operator>/</operator><name>hadoop</name><operator>/</operator><name>hdfs</name><operator>/</operator><name>server</name><operator>/</operator><name>namenode</name><operator>/</operator><name><name>NameNode</name><operator>.</operator><name>java</name></name> <operator>|</operator>  <literal type="number">4</literal> <operator>+</operator><operator>-</operator>
 <operator>...</operator><operator>/</operator><name>hadoop</name><operator>-</operator><name>hdfs</name><operator>/</operator><name>src</name><operator>/</operator><name>main</name><operator>/</operator><name>proto</name><operator>/</operator><name><name>hdfs</name><operator>.</operator><name>proto</name></name>     <operator>|</operator>  <literal type="number">1</literal> <operator>+</operator>
 <operator>...</operator><operator>/</operator><name>org</name><operator>/</operator><name>apache</name><operator>/</operator><name>hadoop</name><operator>/</operator><name>hdfs</name><operator>/</operator><name><name>TestHDFSTrash</name><operator>.</operator><name>java</name></name> <operator>|</operator> <literal type="number">59</literal> <operator>++</operator><operator>++</operator><operator>++</operator><operator>++</operator><operator>++</operator><operator>++</operator><operator>++</operator><operator>++</operator><operator>+</operator><operator>--</operator>
 <literal type="number">13</literal> <name>files</name> <name>changed</name></expr><operator>,</operator> <expr><literal type="number">127</literal> <call><name>insertions</name><argument_list>(<argument><expr><operator>+</operator></expr></argument>)</argument_list></call></expr><operator>,</operator> <expr><literal type="number">35</literal> <call><name>deletions</name><argument_list>(<argument><expr><operator>-</operator></expr></argument>)</argument_list></call>

<name>diff</name> <operator>--</operator><name>git</name> <name>a</name><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>-</operator><name>project</name><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>/</operator><name><name>CHANGES</name><operator>.</operator><name>txt</name></name> <name>b</name><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>-</operator><name>project</name><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>/</operator><name><name>CHANGES</name><operator>.</operator><name>txt</name></name>
<name>index</name> <name>c4ec4a783bb</name><operator>..</operator><name>e0fb6e87e0d</name> <literal type="number">100644</literal>
<operator>--</operator> <name>a</name><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>-</operator><name>project</name><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>/</operator><name><name>CHANGES</name><operator>.</operator><name>txt</name></name>
<operator>++</operator> <name>b</name><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>-</operator><name>project</name><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>/</operator><name><name>CHANGES</name><operator>.</operator><name>txt</name></name>
@@ <operator>-</operator><literal type="number">198</literal></expr><operator>,</operator><expr><literal type="number">6</literal> <operator>+</operator><literal type="number">198</literal></expr><operator>,</operator><expr><literal type="number">8</literal> @@ <name>Branch</name><operator>-</operator><literal type="number">2</literal> <operator>(</operator> <name>Unreleased</name> <name>changes</name> <operator>)</operator>
     <name>HADOOP</name><operator>-</operator><literal type="number">8388.</literal> <name>Remove</name> <name>unused</name> <name>BlockLocation</name> <name><name>serialization</name><operator>.</operator></name>
     (<name>Colin</name> <name>Patrick</name> <name>McCabe</name> <name>via</name> <name>eli</name></expr></expr_stmt>)
 
    <expr_stmt><expr><name>HADOOP</name><operator>-</operator><literal type="number">8689.</literal> <name>Make</name> <name>trash</name> <name>a</name> <name>server</name> <name>side</name> <name>configuration</name> <name><name>option</name><operator>.</operator></name> (<name>eli</name></expr></expr_stmt>)

   <expr_stmt><expr><name>NEW</name> <name>FEATURES</name>
  
     <name>HDFS</name><operator>-</operator><literal type="number">3042.</literal> <name>Automatic</name> <name>failover</name> <name>support</name></expr></expr_stmt> <for>for NameNode HA <control>(<init><expr><name>todd</name></expr></init>)</control><block type="pseudo"><block_content>
<expr_stmt><expr><name>diff</name> <operator>--</operator><name>git</name> <name>a</name><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>-</operator><name>project</name><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>/</operator><name>src</name><operator>/</operator><name>main</name><operator>/</operator><name>java</name><operator>/</operator><name>org</name><operator>/</operator><name>apache</name><operator>/</operator><name>hadoop</name><operator>/</operator><name>fs</name><operator>/</operator><name><name>FileSystem</name><operator>.</operator><name>java</name></name> <name>b</name><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>-</operator><name>project</name><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>/</operator><name>src</name><operator>/</operator><name>main</name><operator>/</operator><name>java</name><operator>/</operator><name>org</name><operator>/</operator><name>apache</name><operator>/</operator><name>hadoop</name><operator>/</operator><name>fs</name><operator>/</operator><name><name>FileSystem</name><operator>.</operator><name>java</name></name>
<name>index</name> <name>c28e25340b2</name><operator>..</operator><literal type="number">13881c776f0</literal> <literal type="number">100644</literal>
<operator>--</operator> <name>a</name><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>-</operator><name>project</name><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>/</operator><name>src</name><operator>/</operator><name>main</name><operator>/</operator><name>java</name><operator>/</operator><name>org</name><operator>/</operator><name>apache</name><operator>/</operator><name>hadoop</name><operator>/</operator><name>fs</name><operator>/</operator><name><name>FileSystem</name><operator>.</operator><name>java</name></name>
<operator>++</operator> <name>b</name><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>-</operator><name>project</name><operator>/</operator><name>hadoop</name><operator>-</operator><name>common</name><operator>/</operator><name>src</name><operator>/</operator><name>main</name><operator>/</operator><name>java</name><operator>/</operator><name>org</name><operator>/</operator><name>apache</name><operator>/</operator><name>hadoop</name><operator>/</operator><name>fs</name><operator>/</operator><name><name>FileSystem</name><operator>.</operator><name>java</name></name>
@@ <operator>-</operator><literal type="number">661</literal></expr><operator>,</operator><expr><literal type="number">7</literal> <operator>+</operator><literal type="number">661</literal></expr><operator>,</operator><expr><literal type="number">9</literal> @@ <specifier>public</specifier> <name>FsServerDefaults</name> <call><name>getServerDefaults</name><argument_list>()</argument_list></call> <throws>throws <argument><expr><name>IOException</name> <block>{
         <expr><literal type="number">64</literal> <operator>*</operator> <literal type="number">1024</literal></expr>, 
         <argument><expr><call><name>getDefaultReplication</name><argument_list>()</argument_list></call></expr></argument>,
         <argument><expr><call><name><name>conf</name><operator>.</operator><name>getInt</name></name><argument_list>(<argument><expr><literal type="string">"io.file.buffer.size"</literal></expr></argument>, <argument><expr><literal type="number">4096</literal></expr></argument>)</argument_list></call></expr></argument>,
        <argument><expr><literal type="boolean">false</literal></expr></argument></block></expr></argument></throws></expr></expr_stmt></block_content></block></for>)<empty_stmt>;</empty_stmt>
        <expr_stmt><expr><literal type="boolean">false</literal></expr><operator>,</operator>
        <comment type="line">// NB: ignoring the client trash configuration</comment>
        <expr><name><name>CommonConfigurationKeysPublic</name><operator>.</operator><name>FS_TRASH_INTERVAL_DEFAULT</name></name></expr></expr_stmt>)<empty_stmt>;</empty_stmt>
   }
 
   <comment type="block" format="javadoc">/**
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FsServerDefaults.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FsServerDefaults.java
index f019593a107..274311e6682 100644
-- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FsServerDefaults.java
++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FsServerDefaults.java
@@ -49,19 +49,21 @@ public Writable newInstance() {
   private short replication;
   private int fileBufferSize;
   private boolean encryptDataTransfer;
  private long trashInterval;
 
   public FsServerDefaults() {
   }
 
   public FsServerDefaults(long blockSize, int bytesPerChecksum,
       int writePacketSize, short replication, int fileBufferSize,
      boolean encryptDataTransfer) {
      boolean encryptDataTransfer, long trashInterval) {
     this.blockSize = blockSize;
     this.bytesPerChecksum = bytesPerChecksum;
     this.writePacketSize = writePacketSize;
     this.replication = replication;
     this.fileBufferSize = fileBufferSize;
     this.encryptDataTransfer = encryptDataTransfer;
    this.trashInterval = trashInterval;
   }
 
   public long getBlockSize() {
@@ -88,6 +90,10 @@ public boolean getEncryptDataTransfer() {
     return encryptDataTransfer;
   }
 
  public long getTrashInterval() {
    return trashInterval;
  }

   // /////////////////////////////////////////
   // Writable
   // /////////////////////////////////////////
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicyDefault.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicyDefault.java
index b6e9e880a1c..07870df1a62 100644
-- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicyDefault.java
++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicyDefault.java
@@ -34,7 +34,6 @@
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.classification.InterfaceStability;
 import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
 import org.apache.hadoop.fs.Options.Rename;
 import org.apache.hadoop.fs.permission.FsAction;
 import org.apache.hadoop.fs.permission.FsPermission;
@@ -66,6 +65,7 @@
 
   private Path current;
   private Path homesParent;
  private long emptierInterval;
 
   public TrashPolicyDefault() { }
 
@@ -79,8 +79,27 @@ public void initialize(Configuration conf, FileSystem fs, Path home) {
     this.trash = new Path(home, TRASH);
     this.homesParent = home.getParent();
     this.current = new Path(trash, CURRENT);
    this.deletionInterval = (long) (conf.getFloat(FS_TRASH_INTERVAL_KEY,
                                    FS_TRASH_INTERVAL_DEFAULT) *  MSECS_PER_MINUTE);
    long trashInterval = 0;
    try {
      trashInterval = fs.getServerDefaults(home).getTrashInterval();
    } catch (IOException ioe) {
      LOG.warn("Unable to get server defaults", ioe);
    }
    // If the trash interval is not configured or is disabled on the
    // server side then check the config which may be client side.
    if (0 == trashInterval) {
      this.deletionInterval = (long)(conf.getFloat(
          FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)
          * MSECS_PER_MINUTE);
    } else {
      this.deletionInterval = trashInterval * MSECS_PER_MINUTE;
    }
    // For the checkpoint interval use the given config instead of
    // checking the server as it's OK if a client starts an emptier
    // with a different interval than the server.
    this.emptierInterval = (long)(conf.getFloat(
        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)
        * MSECS_PER_MINUTE);
   }
   
   private Path makeTrashRelativePath(Path basePath, Path rmFilePath) {
@@ -89,7 +108,7 @@ private Path makeTrashRelativePath(Path basePath, Path rmFilePath) {
 
   @Override
   public boolean isEnabled() {
    return (deletionInterval != 0);
    return deletionInterval != 0;
   }
 
   @Override
@@ -223,7 +242,7 @@ public Path getCurrentTrashDir() {
 
   @Override
   public Runnable getEmptier() throws IOException {
    return new Emptier(getConf());
    return new Emptier(getConf(), emptierInterval);
   }
 
   private class Emptier implements Runnable {
@@ -231,16 +250,14 @@ public Runnable getEmptier() throws IOException {
     private Configuration conf;
     private long emptierInterval;
 
    Emptier(Configuration conf) throws IOException {
    Emptier(Configuration conf, long emptierInterval) throws IOException {
       this.conf = conf;
      this.emptierInterval = (long) (conf.getFloat(FS_TRASH_CHECKPOINT_INTERVAL_KEY,
                                     FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT) *
                                     MSECS_PER_MINUTE);
      if (this.emptierInterval &gt; deletionInterval ||
          this.emptierInterval == 0) {
        LOG.warn("The configured interval for checkpoint is " +
                 this.emptierInterval + " minutes." +
                 " Using interval of " + deletionInterval +
      this.emptierInterval = emptierInterval;
      if (emptierInterval &gt; deletionInterval || emptierInterval == 0) {
        LOG.info("The configured checkpoint interval is " +
                 (emptierInterval / MSECS_PER_MINUTE) + " minutes." +
                 " Using an interval of " +
                 (deletionInterval / MSECS_PER_MINUTE) +
                  " minutes that is used for deletion instead");
         this.emptierInterval = deletionInterval;
       }
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/ftp/FtpConfigKeys.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/ftp/FtpConfigKeys.java
index b646dcaf2c1..0bb5de7faee 100644
-- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/ftp/FtpConfigKeys.java
++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/ftp/FtpConfigKeys.java
@@ -45,6 +45,7 @@
                                                 "ftp.client-write-packet-size";
   public static final int     CLIENT_WRITE_PACKET_SIZE_DEFAULT = 64*1024;
   public static final boolean ENCRYPT_DATA_TRANSFER_DEFAULT = false;
  public static final long    FS_TRASH_INTERVAL_DEFAULT = 0;
   
   protected static FsServerDefaults getServerDefaults() throws IOException {
     return new FsServerDefaults(
@@ -53,7 +54,8 @@ protected static FsServerDefaults getServerDefaults() throws IOException {
         CLIENT_WRITE_PACKET_SIZE_DEFAULT,
         REPLICATION_DEFAULT,
         STREAM_BUFFER_SIZE_DEFAULT,
        ENCRYPT_DATA_TRANSFER_DEFAULT);
        ENCRYPT_DATA_TRANSFER_DEFAULT,
        FS_TRASH_INTERVAL_DEFAULT);
   }
 }
   
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/local/LocalConfigKeys.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/local/LocalConfigKeys.java
index da767d29dc3..76626c3aa03 100644
-- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/local/LocalConfigKeys.java
++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/local/LocalConfigKeys.java
@@ -44,6 +44,7 @@
                                                 "file.client-write-packet-size";
   public static final int CLIENT_WRITE_PACKET_SIZE_DEFAULT = 64*1024;
   public static final boolean ENCRYPT_DATA_TRANSFER_DEFAULT = false;
  public static final long FS_TRASH_INTERVAL_DEFAULT = 0;
 
   public static FsServerDefaults getServerDefaults() throws IOException {
     return new FsServerDefaults(
@@ -52,7 +53,8 @@ public static FsServerDefaults getServerDefaults() throws IOException {
         CLIENT_WRITE_PACKET_SIZE_DEFAULT,
         REPLICATION_DEFAULT,
         STREAM_BUFFER_SIZE_DEFAULT,
        ENCRYPT_DATA_TRANSFER_DEFAULT);
        ENCRYPT_DATA_TRANSFER_DEFAULT,
        FS_TRASH_INTERVAL_DEFAULT);
   }
 }
   
diff --git a/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml b/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
index 25d5798de99..ca9210b6191 100644
-- a/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
++ b/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
@@ -351,8 +351,12 @@
   &lt;name&gt;fs.trash.interval&lt;/name&gt;
   &lt;value&gt;0&lt;/value&gt;
   &lt;description&gt;Number of minutes after which the checkpoint
  gets deleted.
  If zero, the trash feature is disabled.
  gets deleted.  If zero, the trash feature is disabled.
  This option may be configured both on the server and the
  client. If trash is disabled server side then the client
  side configuration is checked. If trash is enabled on the
  server side then the value configured on the server is
  used and the client configuration value is ignored.
   &lt;/description&gt;
 &lt;/property&gt;
 
@@ -360,7 +364,8 @@
   &lt;name&gt;fs.trash.checkpoint.interval&lt;/name&gt;
   &lt;value&gt;0&lt;/value&gt;
   &lt;description&gt;Number of minutes between trash checkpoints.
  Should be smaller or equal to fs.trash.interval.
  Should be smaller or equal to fs.trash.interval. If zero,
  the value is set to the value of fs.trash.interval.
   Every time the checkpointer runs it creates a new checkpoint 
   out of current and removes checkpoints created more than 
   fs.trash.interval minutes ago.
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestTrash.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestTrash.java
index d85b60a9936..8bfa7185b02 100644
-- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestTrash.java
++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestTrash.java
@@ -111,10 +111,10 @@ public static void trashShell(final Configuration conf, final Path base,
       throws IOException {
     FileSystem fs = FileSystem.get(conf);
 
    conf.set(FS_TRASH_INTERVAL_KEY, "0"); // disabled
    conf.setLong(FS_TRASH_INTERVAL_KEY, 0); // disabled
     assertFalse(new Trash(conf).isEnabled());
 
    conf.set(FS_TRASH_INTERVAL_KEY, "10"); // 10 minute
    conf.setLong(FS_TRASH_INTERVAL_KEY, 10); // 10 minute
     assertTrue(new Trash(conf).isEnabled());
 
     FsShell shell = new FsShell();
@@ -435,7 +435,7 @@ public static void trashShell(final Configuration conf, final Path base,
   }
 
   public static void trashNonDefaultFS(Configuration conf) throws IOException {
    conf.set(FS_TRASH_INTERVAL_KEY, "10"); // 10 minute
    conf.setLong(FS_TRASH_INTERVAL_KEY, 10); // 10 minute
     // attempt non-default FileSystem trash
     {
       final FileSystem lfs = FileSystem.getLocal(conf);
@@ -580,7 +580,7 @@ public static void performanceTestDeleteSameFile() throws IOException{
     FileSystem fs = FileSystem.getLocal(conf);
     
     conf.set("fs.defaultFS", fs.getUri().toString());
    conf.set(FS_TRASH_INTERVAL_KEY, "10"); //minutes..
    conf.setLong(FS_TRASH_INTERVAL_KEY, 10); //minutes..
     FsShell shell = new FsShell();
     shell.setConf(conf);
     //Path trashRoot = null;
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java
index 44863b2b289..1361c47afc2 100644
-- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java
++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/PBHelper.java
@@ -1002,7 +1002,8 @@ public static FsServerDefaults convert(FsServerDefaultsProto fs) {
         fs.getBlockSize(), fs.getBytesPerChecksum(), 
         fs.getWritePacketSize(), (short) fs.getReplication(),
         fs.getFileBufferSize(),
        fs.getEncryptDataTransfer());
        fs.getEncryptDataTransfer(),
        fs.getTrashInterval());
   }
   
   public static FsServerDefaultsProto convert(FsServerDefaults fs) {
@@ -1013,7 +1014,8 @@ public static FsServerDefaultsProto convert(FsServerDefaults fs) {
       setWritePacketSize(fs.getWritePacketSize())
       .setReplication(fs.getReplication())
       .setFileBufferSize(fs.getFileBufferSize())
      .setEncryptDataTransfer(fs.getEncryptDataTransfer()).build();
      .setEncryptDataTransfer(fs.getEncryptDataTransfer())
      .setTrashInterval(fs.getTrashInterval()).build();
   }
   
   public static FsPermissionProto convert(FsPermission p) {
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
index 7887eafe374..14f4e0b114b 100644
-- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
@@ -19,6 +19,8 @@
 
 import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT;
 import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY;
import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;
import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;
 import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_BLOCK_SIZE_DEFAULT;
 import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_BLOCK_SIZE_KEY;
 import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_DEFAULT;
@@ -104,6 +106,7 @@
 import org.apache.hadoop.HadoopIllegalArgumentException;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.CommonConfigurationKeysPublic;
 import org.apache.hadoop.fs.ContentSummary;
 import org.apache.hadoop.fs.CreateFlag;
 import org.apache.hadoop.fs.FileAlreadyExistsException;
@@ -479,7 +482,8 @@ public static FSNamesystem loadFromDisk(Configuration conf,
           conf.getInt(DFS_CLIENT_WRITE_PACKET_SIZE_KEY, DFS_CLIENT_WRITE_PACKET_SIZE_DEFAULT),
           (short) conf.getInt(DFS_REPLICATION_KEY, DFS_REPLICATION_DEFAULT),
           conf.getInt(IO_FILE_BUFFER_SIZE_KEY, IO_FILE_BUFFER_SIZE_DEFAULT),
          conf.getBoolean(DFS_ENCRYPT_DATA_TRANSFER_KEY, DFS_ENCRYPT_DATA_TRANSFER_DEFAULT));
          conf.getBoolean(DFS_ENCRYPT_DATA_TRANSFER_KEY, DFS_ENCRYPT_DATA_TRANSFER_DEFAULT),
          conf.getLong(FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT));
       
       this.maxFsObjects = conf.getLong(DFS_NAMENODE_MAX_OBJECTS_KEY, 
                                        DFS_NAMENODE_MAX_OBJECTS_DEFAULT);
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java
index 2df693b3c4e..083b16be689 100644
-- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java
++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java
@@ -511,9 +511,7 @@ private void stopCommonServices() {
   }
   
   private void startTrashEmptier(Configuration conf) throws IOException {
    long trashInterval = conf.getLong(
        CommonConfigurationKeys.FS_TRASH_INTERVAL_KEY,
        CommonConfigurationKeys.FS_TRASH_INTERVAL_DEFAULT);
    long trashInterval = namesystem.getServerDefaults().getTrashInterval();  
     if (trashInterval == 0) {
       return;
     } else if (trashInterval &lt; 0) {
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/hdfs.proto b/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/hdfs.proto
index a640ddaf49d..019fb58558e 100644
-- a/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/hdfs.proto
++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/hdfs.proto
@@ -188,6 +188,7 @@ message FsServerDefaultsProto {
   required uint32 replication = 4; // Actually a short - only 16 bits used
   required uint32 fileBufferSize = 5;
   optional bool encryptDataTransfer = 6 [default = false];
  optional uint64 trashInterval = 7 [default = 0];
 }
 
 
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSTrash.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSTrash.java
index e4124e75c72..b10cab01e04 100644
-- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSTrash.java
++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSTrash.java
@@ -23,12 +23,18 @@
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.fs.TestTrash;
import org.apache.hadoop.fs.Trash;

import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;

 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
 /**
 * This class tests commands from Trash.
 * Test trash using HDFS
  */</comment>
 public <class>class <name>TestHDFSTrash</name> <block>{
   <decl_stmt><decl><type><specifier>private</specifier> <specifier>static</specifier> <name>MiniDFSCluster</name></type> <name>cluster</name> <init>= <expr><literal type="null">null</literal></expr></init></decl>;</decl_stmt>
<annotation>@</annotation>@ <expr_stmt><expr><operator>-</operator><literal type="number">44</literal></expr><operator>,</operator><expr><literal type="number">9</literal> <operator>+</operator><literal type="number">50</literal></expr><operator>,</operator><expr><literal type="number">6</literal> @@ <specifier>public</specifier> <specifier>static</specifier> <name>void</name> <call><name>tearDown</name><argument_list>()</argument_list></call> <block>{
     <if_stmt><if>if <condition>(<expr><name>cluster</name> <operator>!=</operator> <literal type="null">null</literal></expr>)</condition> <block>{<block_content> <expr_stmt><expr><call><name><name>cluster</name><operator>.</operator><name>shutdown</name></name><argument_list>()</argument_list></call></expr>;</expr_stmt> <expr_stmt/></block_content></block></if></if_stmt>}</block></expr></expr_stmt>
   }</block></class>
 
  <comment type="block" format="javadoc">/**
   * Tests Trash on HDFS
   */</comment>
   <function><annotation>@<name>Test</name></annotation>
   <type><specifier>public</specifier> <name>void</name></type> <name>testTrash</name><parameter_list>()</parameter_list> <throws>throws <argument><expr><name>IOException</name></expr></argument></throws> <block>{<block_content>
     <expr_stmt><expr><call><name><name>TestTrash</name><operator>.</operator><name>trashShell</name></name><argument_list>(<argument><expr><call><name><name>cluster</name><operator>.</operator><name>getFileSystem</name></name><argument_list>()</argument_list></call></expr></argument>, <argument><expr><operator>new</operator> <call><name>Path</name><argument_list>(<argument><expr><literal type="string">"/"</literal></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>
<annotation>@</annotation>@ <expr_stmt><expr><operator>-</operator><literal type="number">60</literal></expr><operator>,</operator><expr><literal type="number">4</literal> <operator>+</operator><literal type="number">63</literal></expr><operator>,</operator><expr><literal type="number">52</literal> @@ <specifier>public</specifier> <name>void</name> <call><name>testNonDefaultFS</name><argument_list>()</argument_list></call> <throws>throws <argument><expr><name>IOException</name> <block>{
     <expr><call><name><name>TestTrash</name><operator>.</operator><name>trashNonDefaultFS</name></name><argument_list>(<argument><expr><name>conf</name></expr></argument>)</argument_list></call></expr></block></expr></argument></throws></expr>;</expr_stmt>
   </block_content>}</block></function>
 
  <comment type="block" format="javadoc">/** Clients should always use trash if enabled server side */</comment>
  <function><annotation>@<name>Test</name></annotation>
  <type><specifier>public</specifier> <name>void</name></type> <name>testTrashEnabledServerSide</name><parameter_list>()</parameter_list> <throws>throws <argument><expr><name>IOException</name></expr></argument></throws> <block>{<block_content>
    <decl_stmt><decl><type><name>Configuration</name></type> <name>serverConf</name> <init>= <expr><operator>new</operator> <call><name>HdfsConfiguration</name><argument_list>()</argument_list></call></expr></init></decl>;</decl_stmt>
    <decl_stmt><decl><type><name>Configuration</name></type> <name>clientConf</name> <init>= <expr><operator>new</operator> <call><name>Configuration</name><argument_list>()</argument_list></call></expr></init></decl>;</decl_stmt>

    <comment type="line">// Enable trash on the server and client</comment>
    <expr_stmt><expr><call><name><name>serverConf</name><operator>.</operator><name>setLong</name></name><argument_list>(<argument><expr><name>FS_TRASH_INTERVAL_KEY</name></expr></argument>, <argument><expr><literal type="number">1</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
    <expr_stmt><expr><call><name><name>clientConf</name><operator>.</operator><name>setLong</name></name><argument_list>(<argument><expr><name>FS_TRASH_INTERVAL_KEY</name></expr></argument>, <argument><expr><literal type="number">1</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>

    <decl_stmt><decl><type><name>MiniDFSCluster</name></type> <name>cluster2</name> <init>= <expr><literal type="null">null</literal></expr></init></decl>;</decl_stmt>
    <try>try <block>{<block_content>
      <expr_stmt><expr><name>cluster2</name> <operator>=</operator> <operator>new</operator> <call><name><name>MiniDFSCluster</name><operator>.</operator><name>Builder</name></name><argument_list>(<argument><expr><name>serverConf</name></expr></argument>)</argument_list></call><operator>.</operator><call><name>numDataNodes</name><argument_list>(<argument><expr><literal type="number">1</literal></expr></argument>)</argument_list></call><operator>.</operator><call><name>build</name><argument_list>()</argument_list></call></expr>;</expr_stmt>
      <decl_stmt><decl><type><name>FileSystem</name></type> <name>fs</name> <init>= <expr><call><name><name>cluster2</name><operator>.</operator><name>getFileSystem</name></name><argument_list>()</argument_list></call></expr></init></decl>;</decl_stmt>
      <expr_stmt><expr><call><name>assertTrue</name><argument_list>(<argument><expr><operator>new</operator> <call><name>Trash</name><argument_list>(<argument><expr><name>fs</name></expr></argument>, <argument><expr><name>clientConf</name></expr></argument>)</argument_list></call><operator>.</operator><call><name>isEnabled</name><argument_list>()</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>

      <comment type="line">// Disabling trash on the client is ignored</comment>
      <expr_stmt><expr><call><name><name>clientConf</name><operator>.</operator><name>setLong</name></name><argument_list>(<argument><expr><name>FS_TRASH_INTERVAL_KEY</name></expr></argument>, <argument><expr><literal type="number">0</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
      <expr_stmt><expr><call><name>assertTrue</name><argument_list>(<argument><expr><operator>new</operator> <call><name>Trash</name><argument_list>(<argument><expr><name>fs</name></expr></argument>, <argument><expr><name>clientConf</name></expr></argument>)</argument_list></call><operator>.</operator><call><name>isEnabled</name><argument_list>()</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>
    </block_content>}</block> <finally>finally <block>{<block_content>
      <if_stmt><if>if <condition>(<expr><name>cluster2</name> <operator>!=</operator> <literal type="null">null</literal></expr>)</condition><block type="pseudo"><block_content> <expr_stmt><expr><call><name><name>cluster2</name><operator>.</operator><name>shutdown</name></name><argument_list>()</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>
    </block_content>}</block></finally></try>
  </block_content>}</block></function>

  <comment type="block" format="javadoc">/** Clients should always use trash if enabled client side */</comment>
  <function><annotation>@<name>Test</name></annotation>
  <type><specifier>public</specifier> <name>void</name></type> <name>testTrashEnabledClientSide</name><parameter_list>()</parameter_list> <throws>throws <argument><expr><name>IOException</name></expr></argument></throws> <block>{<block_content>
    <decl_stmt><decl><type><name>Configuration</name></type> <name>serverConf</name> <init>= <expr><operator>new</operator> <call><name>HdfsConfiguration</name><argument_list>()</argument_list></call></expr></init></decl>;</decl_stmt>
    <decl_stmt><decl><type><name>Configuration</name></type> <name>clientConf</name> <init>= <expr><operator>new</operator> <call><name>Configuration</name><argument_list>()</argument_list></call></expr></init></decl>;</decl_stmt>
    
    <comment type="line">// Disable server side</comment>
    <expr_stmt><expr><call><name><name>serverConf</name><operator>.</operator><name>setLong</name></name><argument_list>(<argument><expr><name>FS_TRASH_INTERVAL_KEY</name></expr></argument>, <argument><expr><literal type="number">0</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>

    <decl_stmt><decl><type><name>MiniDFSCluster</name></type> <name>cluster2</name> <init>= <expr><literal type="null">null</literal></expr></init></decl>;</decl_stmt>
    <try>try <block>{<block_content>
      <expr_stmt><expr><name>cluster2</name> <operator>=</operator> <operator>new</operator> <call><name><name>MiniDFSCluster</name><operator>.</operator><name>Builder</name></name><argument_list>(<argument><expr><name>serverConf</name></expr></argument>)</argument_list></call><operator>.</operator><call><name>numDataNodes</name><argument_list>(<argument><expr><literal type="number">1</literal></expr></argument>)</argument_list></call><operator>.</operator><call><name>build</name><argument_list>()</argument_list></call></expr>;</expr_stmt>

      <comment type="line">// Client side is disabled by default</comment>
      <decl_stmt><decl><type><name>FileSystem</name></type> <name>fs</name> <init>= <expr><call><name><name>cluster2</name><operator>.</operator><name>getFileSystem</name></name><argument_list>()</argument_list></call></expr></init></decl>;</decl_stmt>
      <expr_stmt><expr><call><name>assertFalse</name><argument_list>(<argument><expr><operator>new</operator> <call><name>Trash</name><argument_list>(<argument><expr><name>fs</name></expr></argument>, <argument><expr><name>clientConf</name></expr></argument>)</argument_list></call><operator>.</operator><call><name>isEnabled</name><argument_list>()</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>

      <comment type="line">// Enabling on the client works even though its disabled on the server</comment>
      <expr_stmt><expr><call><name><name>clientConf</name><operator>.</operator><name>setLong</name></name><argument_list>(<argument><expr><name>FS_TRASH_INTERVAL_KEY</name></expr></argument>, <argument><expr><literal type="number">1</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
      <expr_stmt><expr><call><name>assertTrue</name><argument_list>(<argument><expr><operator>new</operator> <call><name>Trash</name><argument_list>(<argument><expr><name>fs</name></expr></argument>, <argument><expr><name>clientConf</name></expr></argument>)</argument_list></call><operator>.</operator><call><name>isEnabled</name><argument_list>()</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>
    </block_content>}</block> <finally>finally <block>{<block_content>
      <if_stmt><if>if <condition>(<expr><name>cluster2</name> <operator>!=</operator> <literal type="null">null</literal></expr>)</condition><block type="pseudo"><block_content> <expr_stmt><expr><call><name><name>cluster2</name><operator>.</operator><name>shutdown</name></name><argument_list>()</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>
    </block_content>}</block></finally></try>
  </block_content>}</block></function>
 }
- 
<expr><literal type="number">2.19.1.windows</literal><literal type="number">.1</literal></expr>

</unit>
